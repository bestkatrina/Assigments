{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Ass2_main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgUSJk2zSWwg"
      },
      "source": [
        "## Download dataset from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUBAPlHSTDaA"
      },
      "source": [
        "# Code to download file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "id = '1fto6uicrRohYAp-Yo9gAAf_27t2btCp6'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('2020-comp5046-a2.zip')\n",
        "!unzip -d /content/ /content/2020-comp5046-a2.zip > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giW1fTlIaErn",
        "outputId": "53c575e5-e7de-4a58-bfb2-b63a319cf2d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "!cat train.csv | wc -l\n",
        "!cat val.csv | wc -l\n",
        "!cat test.csv | wc -l\n",
        "!head -n 10 test.csv\n",
        "!head -n 10 sample\\ submission.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3001\n",
            "701\n",
            "3685\n",
            "Sentence,NER\n",
            "-docstart-,\n",
            "\"soccer - japan get lucky win , china in surprise defeat .\",\n",
            "nadim ladki,\n",
            "\"al-ain , united arab emirates 1996-12-06\",\n",
            "japan began the defence of their asian cup title with a lucky 2-1 win against syria in a group c championship match on friday .,\n",
            "\"but china saw their luck desert them in the second match of the group , crashing to a surprise 2-0 defeat to newcomers uzbekistan .\",\n",
            "china controlled most of the match and saw several chances missed until the 78th minute when uzbek striker igor shkvyrin took advantage of a misdirected defensive header to lob the ball over the advancing chinese keeper and into an empty net .,\n",
            "\"oleg shatskiku made sure of the win in injury time , hitting an unstoppable left foot shot from just outside the area .\",\n",
            "the former soviet republic was playing in an asian cup finals tie for the first time .,\n",
            "Id,Predicted\n",
            "0,O\n",
            "1,O\n",
            "2,O\n",
            "3,O\n",
            "4,O\n",
            "5,O\n",
            "6,O\n",
            "7,O\n",
            "8,O\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ue05jw0ecn3",
        "outputId": "119d688f-3fdc-4e27-e12f-9b8e13d0b2ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv('train.csv',header=0,sep=',')\n",
        "val_df = pd.read_csv('val.csv',header=0,sep=',')\n",
        "test_df = pd.read_csv('test.csv',header=0,sep=',')\n",
        "train_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>NER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-docstart-</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>eu rejects german call to boycott british lamb .</td>\n",
              "      <td>I-ORG O I-MISC O O O I-MISC O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>peter blackburn</td>\n",
              "      <td>I-PER I-PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>brussels 1996-08-22</td>\n",
              "      <td>I-LOC O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the european commission said on thursday it di...</td>\n",
              "      <td>O I-ORG I-ORG O O O O O O I-MISC O O O O O I-M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>hovercrafts will soon be plying the waters of ...</td>\n",
              "      <td>O O O O O O O O O I-LOC O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>two russian-built hovercrafts , capable of car...</td>\n",
              "      <td>O I-MISC O O O O O O O O O O O O O O O O O O O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>the use of riverways in the region has been ma...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O I-LOC O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>-docstart-</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>hk 's tsang to visit indonesia , new zealand .</td>\n",
              "      <td>I-LOC O I-PER O O I-LOC O I-LOC I-LOC O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Sentence                                                NER\n",
              "0                                            -docstart-                                                  O\n",
              "1      eu rejects german call to boycott british lamb .                    I-ORG O I-MISC O O O I-MISC O O\n",
              "2                                       peter blackburn                                        I-PER I-PER\n",
              "3                                   brussels 1996-08-22                                            I-LOC O\n",
              "4     the european commission said on thursday it di...  O I-ORG I-ORG O O O O O O I-MISC O O O O O I-M...\n",
              "...                                                 ...                                                ...\n",
              "2995  hovercrafts will soon be plying the waters of ...  O O O O O O O O O I-LOC O O O O O O O O O O O ...\n",
              "2996  two russian-built hovercrafts , capable of car...  O I-MISC O O O O O O O O O O O O O O O O O O O...\n",
              "2997  the use of riverways in the region has been ma...  O O O O O O O O O O O O O O O O O O I-LOC O O ...\n",
              "2998                                         -docstart-                                                  O\n",
              "2999     hk 's tsang to visit indonesia , new zealand .            I-LOC O I-PER O O I-LOC O I-LOC I-LOC O\n",
              "\n",
              "[3000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPw_phQjjiZp"
      },
      "source": [
        "def read_data(sentences,ners=None):\n",
        "  input_data = [sent.split(' ') for sent in sentences]\n",
        "  if ners:\n",
        "    target_data = [ner.split(' ') for ner in ners]\n",
        "  else:\n",
        "    target_data = None\n",
        "  return input_data,target_data\n",
        "\n",
        "train_data, target_y_train = read_data(train_df.Sentence.to_list(),train_df.NER.to_list())\n",
        "validation_data, target_y_validation = read_data(val_df.Sentence.to_list(),val_df.NER.to_list())\n",
        "test_data,_ = read_data(test_df.Sentence.to_list())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGBICBIWk0k3"
      },
      "source": [
        "word_to_ix = {}\n",
        "for sentence in train_data+validation_data+test_data:\n",
        "    for word in sentence:\n",
        "        word = word.lower()\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "word_list = list(word_to_ix.keys())\n",
        "\n",
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "tag_to_ix = {START_TAG:0, STOP_TAG:1}\n",
        "for tags in target_y_train+target_y_validation:\n",
        "    for tag in tags:\n",
        "        if tag not in tag_to_ix:\n",
        "            tag_to_ix[tag] = len(tag_to_ix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDNVexQ1Sdwr"
      },
      "source": [
        "## Word2vec embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPerFVG0mnZz",
        "outputId": "a443a17c-cc17-4302-bc8e-f030fb3ecd02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "import gensim.downloader as api\n",
        "word_emb_model = api.load(\"glove-wiki-gigaword-300\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[================================================--] 97.5% 366.8/376.1MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV33w-lAnGyW",
        "outputId": "3802221a-8aa0-4e8f-cc7c-828da2e4b760",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "EMBEDDING_DIM = word_emb_model.vector_size\n",
        "oov = np.random.uniform(-0.25, 0.25, EMBEDDING_DIM).round(6)\n",
        "word_embedding_matrix = []\n",
        "for word in word_list:\n",
        "    try:\n",
        "        word_embedding_matrix.append(word_emb_model.get_vector(word))\n",
        "    except:\n",
        "        word_embedding_matrix.append(oov)\n",
        "word_embedding_matrix = np.array(word_embedding_matrix)\n",
        "word_embedding_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13972, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U21O5hqoKaf"
      },
      "source": [
        "def to_index(data, to_ix):\n",
        "    input_index_list = []\n",
        "    for sent in data:\n",
        "        input_index_list.append([to_ix[w] for w in sent])\n",
        "    return input_index_list\n",
        "\n",
        "train_input_index =  to_index(train_data,word_to_ix)\n",
        "train_output_index = to_index(target_y_train,tag_to_ix)\n",
        "val_input_index = to_index(validation_data,word_to_ix)\n",
        "val_output_index = to_index(target_y_validation,tag_to_ix)\n",
        "test_input_index = to_index(test_data,word_to_ix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S19BjxKtn9Uj"
      },
      "source": [
        "## PoS Tag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd-7XvLeNXav",
        "outputId": "ccaa49dc-091a-4b25-dd7e-1b3572b8304b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('treebank')\n",
        "nltk.download('universal_tagset')\n",
        "nltk.download('brown')\n",
        "from nltk.corpus import treebank,brown"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc69CTc5U4CK"
      },
      "source": [
        "train_tag = [[tag for _,tag in nltk.pos_tag(sentence)] for sentence in train_data]\n",
        "validation_tag = [[tag for _,tag in nltk.pos_tag(sentence)] for sentence in validation_data]\n",
        "test_tag = [[tag for _,tag in nltk.pos_tag(sentence)] for sentence in test_data]\n",
        "tag_list =set([tag for tags in train_tag + validation_tag + test_tag for tag in tags])\n",
        "\n",
        "pos_tag_to_idx = {t: i for i, t in enumerate(list(tag_list))}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrHr32Cu4z9P"
      },
      "source": [
        "import torch.nn as nn\n",
        "class PoSTagger(nn.Module):\n",
        "    def __init__(self, pos_tag_idx):\n",
        "        super(PoSTagger, self).__init__()\n",
        "        self.tag_2_index = pos_tag_idx\n",
        "    def tag_to_one_hot(self,tag):\n",
        "        one_hot = np.zeros(len(self.tag_2_index))\n",
        "        one_hot[self.tag_2_index[tag]] = 1\n",
        "        return one_hot\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = x.cpu().numpy().tolist()\n",
        "        x = [word_list[idx] for idx in x]\n",
        "        pos_tag = [tag for _,tag in nltk.pos_tag(x)]\n",
        "        pos_tag_one_hot = np.array([self.tag_to_one_hot(tag) for tag in pos_tag])\n",
        "        return torch.from_numpy(pos_tag_one_hot).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YNDtGG_Ozfu"
      },
      "source": [
        "## Character embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQtWbf0Fz6Vw"
      },
      "source": [
        "char_arr = list(set([char for words in train_data + validation_data + test_data for char in ''.join(words)]))\n",
        "char_arr.sort()\n",
        "# one-hot encoding and decoding \n",
        "num_dic = {n: i+1 for i, n in enumerate(char_arr)}\n",
        "num_dic['P'] = 0 #encoding for padding\n",
        "dic_len = len(num_dic)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQJny-Yn2zaL",
        "outputId": "c90fdf89-5ad2-4e8c-f3e9-12c5eb29d36c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from collections import Counter\n",
        "word_length_cnt=Counter(map(len,word_list)).most_common()\n",
        "word_length_cnt.sort()\n",
        "total_amt=0\n",
        "ratio=0.9\n",
        "for idx,(length,amt) in enumerate(word_length_cnt):\n",
        "  if total_amt/len(word_list)<=ratio:\n",
        "    total_amt += amt\n",
        "  else:\n",
        "    break\n",
        "max_word_len = idx\n",
        "max_word_len"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ_t5I2i22nE"
      },
      "source": [
        "def add_padding(word):\n",
        "  if len(word)>=max_word_len:\n",
        "    return word[:max_word_len]\n",
        "  else:\n",
        "    return word+'P'*(max_word_len-len(word))\n",
        "def make_batch(seq_data):\n",
        "    input_batch = []\n",
        "    target_batch = []\n",
        "    \n",
        "    for seq in seq_data:\n",
        "        after_padding=add_padding(seq)\n",
        "        input_data = [num_dic[n] for n in after_padding]\n",
        "        target = word_embedding_matrix[seq_data.index(seq)]\n",
        "        # convert input to one-hot encoding.\n",
        "        # if input is [3, 4, 4]:\n",
        "        # [[ 0,  0,  0,  1,  0,  0,  0, ... 0]\n",
        "        #  [ 0,  0,  0,  0,  1,  0,  0, ... 0]\n",
        "        #  [ 0,  0,  0,  0,  1,  0,  0, ... 0]]\n",
        "        input_batch.append(np.eye(dic_len)[input_data])\n",
        "        \n",
        "        target_batch.append(target)\n",
        "\n",
        "    return input_batch, target_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcuTx3tb3MIF"
      },
      "source": [
        "# setting hyperparameters\n",
        "# from previous experience, learning_rate more than 0.01 may result in a big loss\n",
        "\n",
        "learning_rate = 0.01\n",
        "n_hidden = 100\n",
        "total_epoch = 500\n",
        "n_input = dic_len\n",
        "n_class = word_embedding_matrix.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aObtx-P3RiL"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "import torch\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.lstm = nn.LSTM(n_input, n_hidden, batch_first =True,bidirectional=True, dropout=0.2)\n",
        "        self.linear = nn.Linear(n_hidden*2,n_class)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        \n",
        "        #h_n of shape (num_layers * num_directions, batch, hidden_size): tensor containing the hidden state for t = seq_len.\n",
        "        lstm_out, (h_n,c_n) = self.lstm(sentence)\n",
        "        #concat the last hidden state from two direction\n",
        "        hidden_out =torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
        "        z = self.linear(hidden_out)\n",
        "        log_output = F.log_softmax(z, dim=1)\n",
        "        return log_output,hidden_out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi4I26Fv3flw"
      },
      "source": [
        "# Preparing input\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "input_batch, target_batch = make_batch(word_list)\n",
        "# Convert input into tensors and move them to GPU by uting tensor.to(device)\n",
        "input_batch_torch = torch.from_numpy(np.array(input_batch)).float().to(device)\n",
        "target_batch_torch = torch.from_numpy(np.array(target_batch)).float().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsBlKX1t3h4j"
      },
      "source": [
        "# Move the model to GPU\n",
        "net = Net().to(device)\n",
        "# Loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
        "for epoch in range(total_epoch):  \n",
        "    \n",
        "    # Set the flag to training\n",
        "    net.train()\n",
        "    # forward + backward + optimize\n",
        "    outputs,_ = net(input_batch_torch) \n",
        "    loss = criterion(outputs, target_batch_torch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    # Set the flag to evaluation, which will 'turn off' the dropout\n",
        "    net.eval()\n",
        "    outputs,_ = net(input_batch_torch) \n",
        "    # Evaluation loss and accuracy calculation\n",
        "    loss = criterion(outputs, target_batch_torch)\n",
        "    if epoch % 20 == 19:\n",
        "      print('Epoch: %d, loss: %.5f' %(epoch + 1, loss.item()))\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBFNw0pwKjAs",
        "outputId": "67e841f3-1cbb-42e7-e11c-475194cb4b5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "torch.save(net,'char_embedding_model.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnC8YbiKGUk5",
        "outputId": "167a0dd1-c0ee-4e79-df7f-cda00a134b20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "id = '1DwHh0Zcvrs28q3vVvJcilc6coUP-ZSJq'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('char_embedding_model.pt')\n",
        "import torch\n",
        "net = torch.load('char_embedding_model.pt')\n",
        "\n",
        "_,hidden_state = net(input_batch_torch)\n",
        "char_embedding_matrix = hidden_state.data\n",
        "char_embedding_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([13972, 200])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXEscWBrhjgb"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5AgRWakkfmT"
      },
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "torch.manual_seed(1)\n",
        "\n",
        "def argmax(vec):\n",
        "    # return the argmax as a python int\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return idx.item()\n",
        "\n",
        "\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + \\\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    ATTN_TYPE_DOT_PRODUCT = \"Dot Product\"\n",
        "    ATTN_TYPE_SCALE_DOT_PRODUCT = \"Scale Dot Product\"\n",
        "\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, pos_tag_idx, hidden_dim,config):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "\n",
        "        self.nlayers = config['nlayers']\n",
        "        self.attn_method = config['attn_method']\n",
        "        self.use_char = config['use_char']\n",
        "        self.use_pos = config['use_pos']\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, word_embedding_matrix.shape[1])\n",
        "        self.char_embeds = nn.Embedding(vocab_size,char_embedding_matrix.shape[1])\n",
        "        self.pos_tagger = PoSTagger(pos_tag_idx)\n",
        "        \"\"\"Here we use the embedding matrix as the initial weights of nn.Embedding\"\"\"\n",
        "        self.word_embeds.weight.data.copy_(torch.from_numpy(word_embedding_matrix))\n",
        "        self.char_embeds.weight.data.copy_(char_embedding_matrix)\n",
        "        self.embedding_dim = word_embedding_matrix.shape[1]\n",
        "        if config['use_char']:\n",
        "            self.embedding_dim += char_embedding_matrix.shape[1]\n",
        "        if config['use_pos']:\n",
        "            self.embedding_dim += len(pos_tag_idx)\n",
        "\n",
        "        self.lstm = nn.LSTM(self.embedding_dim\n",
        "                            , hidden_dim // 2,\n",
        "                            num_layers=self.nlayers,dropout=0.3, bidirectional=True)\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "        \n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2 * self.nlayers, 1, self.hidden_dim // 2).to(device),\n",
        "                torch.randn(2 * self.nlayers, 1, self.hidden_dim // 2).to(device))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def cal_attention(self, q, k, method):\n",
        "        if method == BiLSTM_CRF.ATTN_TYPE_DOT_PRODUCT:\n",
        "            attn_weights = F.softmax(torch.bmm(q, k.permute(1,2,0)),dim=-1)\n",
        "            attn_output = torch.bmm(attn_weights, k.permute(1,0,2))\n",
        "            concat_output = torch.cat((attn_output[0], q[0]), 1)\n",
        "        elif method == BiLSTM_CRF.ATTN_TYPE_SCALE_DOT_PRODUCT:\n",
        "            attn_weights = F.softmax(torch.bmm(q, k.permute(1,2,0)) / np.power(k.shape[2],0.5),dim=-1)\n",
        "            attn_output = torch.bmm(attn_weights, k.permute(1,0,2))\n",
        "            concat_output = torch.cat((attn_output[0], q[0]), 1)\n",
        "\n",
        "            \n",
        "        return concat_output\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        stacked_embeds = []\n",
        "        word2vec_embeds = self.word_embeds(sentence)\n",
        "        stacked_embeds.append(word2vec_embeds)\n",
        "        if self.use_char:\n",
        "            character_embeds = self.char_embeds(sentence)\n",
        "            stacked_embeds.append(character_embeds)\n",
        "        if self.use_pos:\n",
        "            pos_tag_embeds = self.pos_tagger(sentence)\n",
        "            stacked_embeds.append(pos_tag_embeds)\n",
        "        # tfidf_embeds = self.tfidf(sentence)\n",
        "        if len(stacked_embeds) >= 2:\n",
        "            embeds = torch.cat(tuple(stacked_embeds),1).view(len(sentence), 1, -1)\n",
        "        else:\n",
        "            embeds = stacked_embeds[0].view(len(sentence), 1, -1)\n",
        "        embeds = self.dropout(embeds)\n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "        # lstm_out = lstm_out.permute(1,0,2)\n",
        "        # h_n = torch.cat((h_n[-2,:,:],h_n[-1,:,:]),1).unsqueeze(0)\n",
        "        # attn_output,_ = self.attention(lstm_out,h_n)\n",
        "        lstm_out = lstm_out[:,:,:self.hidden_dim // 2] + lstm_out[:,:,self.hidden_dim // 2:]\n",
        "\n",
        "        attn_output = torch.zeros(len(sentence), self.hidden_dim, device=device)\n",
        "\n",
        "        for i in range(len(sentence)):\n",
        "            query = lstm_out[i]\n",
        "            concat_output = self.cal_attention(query.unsqueeze(0), lstm_out, self.attn_method)\n",
        "            attn_output[i] = concat_output\n",
        "        attn_output = attn_output.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(attn_output)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        # print('output shape',feats.shape)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUNHEV1kiDKt"
      },
      "source": [
        "### Function for accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJmu0oSsjLBm"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "def cal_f1(model,input_index,output_index):\n",
        "  ground_truth = list()\n",
        "  predicted = list()\n",
        "  for train_idx,target in zip(input_index,output_index):\n",
        "    \n",
        "    input_torch = torch.tensor(train_idx,dtype=torch.long).to(device)\n",
        "    _,output = model(input_torch)\n",
        "    predicted += output\n",
        "    ground_truth += target\n",
        "  f1 = f1_score(ground_truth,predicted,average='micro')\n",
        "\n",
        "  return ground_truth, predicted, f1\n",
        "\n",
        "def predict(model,input_index):\n",
        "   predicted = list()\n",
        "   for train_idx in input_index:\n",
        "     input_torch = torch.tensor(train_idx,dtype=torch.long).to(device)\n",
        "     _,output = model(input_torch)\n",
        "     predicted += output\n",
        "   return predicted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_82UaXEOhoQQ"
      },
      "source": [
        "### Initialize Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqJp9rj9dNpI"
      },
      "source": [
        "config = {\n",
        "    'nlayers':2,\n",
        "    'use_char':True,\n",
        "    'use_pos':True,\n",
        "    'attn_method':'Scale Dot Product'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyuzZ_et6FD7"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HIDDEN_DIM = 150\n",
        "learning_rate = 0.05\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, pos_tag_to_idx, HIDDEN_DIM,config).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=10,gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9UiokVOjPUn"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN5KaELT46Yw"
      },
      "source": [
        "logs = dict(\n",
        "    epoch=[],\n",
        "    train_loss=[],\n",
        "    val_loss=[],\n",
        "    train_f1=[],\n",
        "    val_f1=[],\n",
        "    nlayers=[],\n",
        "    use_char=[],\n",
        "    use_pos=[],\n",
        "    attn_method=[],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0CMFVSwlLru"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import datetime\n",
        "epochs = 20\n",
        "print(config)\n",
        "for epoch in range(epochs):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "    model.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        # print('input shape',sentence_in.shape)\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    # lr_scheduler.step()\n",
        "    model.eval()\n",
        "    _, _, train_f1 = cal_f1(model,train_input_index,train_output_index)\n",
        "    _, _, val_f1 = cal_f1(model,val_input_index,val_output_index)\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "        val_loss += loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "     \n",
        "    logs['epoch'].append(epoch+1)\n",
        "    logs['train_loss'].append(train_loss)\n",
        "    logs['val_loss'].append(val_loss)\n",
        "    logs['train_f1'].append(train_f1)\n",
        "    logs['val_f1'].append(val_f1)\n",
        "    logs['nlayers'].append(config['nlayers'])\n",
        "    logs['use_char'].append(config['use_char'])\n",
        "    logs['use_pos'].append(config['use_pos'])\n",
        "    logs['attn_method'].append(config['attn_method'])\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train f1: %.4f, val loss: %.2f, val f1: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_f1, val_loss, val_f1, (time2-time1).total_seconds()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGZHRBYipUxw"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(logs)\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=df.epoch, y=df.train_loss,mode='lines',name='training loss')) \n",
        "fig.show()\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=df.epoch, y=df.val_loss,mode='lines',name='validation loss')) \n",
        "fig.show()\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=df.epoch, y=df.train_f1,mode='lines',name='training f1 score')) \n",
        "fig.show()\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=df.epoch, y=df.val_f1,mode='lines',name='validation f1 score')) \n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaibof3X3bMo"
      },
      "source": [
        "## Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQmhtf7m32hq"
      },
      "source": [
        "combinations = [\n",
        "[2,False,False,'Dot Product'],\n",
        "[2,True,False,'Dot Product'],\n",
        "]\n",
        "logs = dict(\n",
        "    epoch=[],\n",
        "    train_loss=[],\n",
        "    val_loss=[],\n",
        "    train_f1=[],\n",
        "    val_f1=[],\n",
        "    nlayers=[],\n",
        "    use_char=[],\n",
        "    use_pos=[],\n",
        "    attn_method=[],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVMEw5UX3VQB",
        "outputId": "f3d01b31-31fe-4220-f809-52e5483535dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        }
      },
      "source": [
        "import datetime\n",
        "for p in combinations:\n",
        "    config = dict(zip(['nlayers','use_char','use_pos','attn_method'],p))\n",
        "    print(config)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    HIDDEN_DIM = 150\n",
        "    learning_rate = 0.05\n",
        "    model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, pos_tag_to_idx, HIDDEN_DIM,config).to(device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=10,gamma=0.1)\n",
        "\n",
        "    epochs = 20\n",
        "    print(config)\n",
        "    for epoch in range(epochs):  \n",
        "        time1 = datetime.datetime.now()\n",
        "        train_loss = 0\n",
        "        model.train()\n",
        "        for i, idxs in enumerate(train_input_index):\n",
        "            tags_index = train_output_index[i]\n",
        "            # Step 1. Remember that Pytorch accumulates gradients.\n",
        "            # We need to clear them out before each instance\n",
        "            model.zero_grad()\n",
        "            # Step 2. Get our inputs ready for the network, that is,\n",
        "            # turn them into Tensors of word indices.\n",
        "            sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "            targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "            # print('input shape',sentence_in.shape)\n",
        "            # Step 3. Run our forward pass.\n",
        "            loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "            # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "            # calling optimizer.step()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "        lr_scheduler.step()\n",
        "        model.eval()\n",
        "        _, _, train_f1 = cal_f1(model,train_input_index,train_output_index)\n",
        "        _, _, val_f1 = cal_f1(model,val_input_index,val_output_index)\n",
        "        val_loss = 0\n",
        "        for i, idxs in enumerate(val_input_index):\n",
        "            tags_index = val_output_index[i]\n",
        "            sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "            targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "            loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "            val_loss += loss.item()\n",
        "        time2 = datetime.datetime.now()\n",
        "\n",
        "        logs['epoch'].append(epoch+1)\n",
        "        logs['train_loss'].append(train_loss)\n",
        "        logs['val_loss'].append(val_loss)\n",
        "        logs['train_f1'].append(train_f1)\n",
        "        logs['val_f1'].append(val_f1)\n",
        "        logs['nlayers'].append(config['nlayers'])\n",
        "        logs['use_char'].append(config['use_char'])\n",
        "        logs['use_pos'].append(config['use_pos'])\n",
        "        logs['attn_method'].append(config['attn_method'])\n",
        "\n",
        "        print(\"Epoch:%d, Training loss: %.2f, train f1: %.4f, val loss: %.2f, val f1: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_f1, val_loss, val_f1, (time2-time1).total_seconds()))\n",
        "    torch.save(model,'bilstm-crf_{}'.format(str(config)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'nlayers': 2, 'use_char': False, 'use_pos': False, 'attn_method': 'Dot Product'}\n",
            "{'nlayers': 2, 'use_char': False, 'use_pos': False, 'attn_method': 'Dot Product'}\n",
            "Epoch:1, Training loss: 13124.55, train f1: 0.9361, val loss: 1485.18, val f1: 0.9247, time: 226.71s\n",
            "Epoch:2, Training loss: 5493.02, train f1: 0.9612, val loss: 1159.76, val f1: 0.9418, time: 231.86s\n",
            "Epoch:3, Training loss: 3966.42, train f1: 0.9678, val loss: 1188.08, val f1: 0.9452, time: 229.27s\n",
            "Epoch:4, Training loss: 2830.68, train f1: 0.9731, val loss: 1195.75, val f1: 0.9513, time: 226.53s\n",
            "Epoch:5, Training loss: 2376.78, train f1: 0.9818, val loss: 1273.66, val f1: 0.9545, time: 224.97s\n",
            "Epoch:6, Training loss: 1916.87, train f1: 0.9816, val loss: 1184.75, val f1: 0.9582, time: 227.15s\n",
            "Epoch:7, Training loss: 1581.11, train f1: 0.9875, val loss: 1081.51, val f1: 0.9615, time: 227.84s\n",
            "Epoch:8, Training loss: 1374.28, train f1: 0.9844, val loss: 1268.17, val f1: 0.9550, time: 227.24s\n",
            "Epoch:9, Training loss: 1111.09, train f1: 0.9892, val loss: 1238.65, val f1: 0.9619, time: 222.26s\n",
            "Epoch:10, Training loss: 967.44, train f1: 0.9937, val loss: 1173.45, val f1: 0.9659, time: 223.94s\n",
            "Epoch:11, Training loss: 743.49, train f1: 0.9970, val loss: 1088.10, val f1: 0.9684, time: 223.26s\n",
            "Epoch:12, Training loss: 671.52, train f1: 0.9977, val loss: 1075.96, val f1: 0.9689, time: 223.46s\n",
            "Epoch:13, Training loss: 586.68, train f1: 0.9978, val loss: 1069.14, val f1: 0.9694, time: 223.71s\n",
            "Epoch:14, Training loss: 567.93, train f1: 0.9980, val loss: 1080.57, val f1: 0.9686, time: 219.94s\n",
            "Epoch:15, Training loss: 536.10, train f1: 0.9981, val loss: 1079.98, val f1: 0.9693, time: 222.71s\n",
            "Epoch:16, Training loss: 506.18, train f1: 0.9985, val loss: 1101.68, val f1: 0.9702, time: 225.41s\n",
            "Epoch:17, Training loss: 479.21, train f1: 0.9982, val loss: 1148.14, val f1: 0.9692, time: 224.29s\n",
            "Epoch:18, Training loss: 466.69, train f1: 0.9987, val loss: 1125.91, val f1: 0.9688, time: 224.32s\n",
            "Epoch:19, Training loss: 469.38, train f1: 0.9990, val loss: 1102.04, val f1: 0.9701, time: 226.76s\n",
            "Epoch:20, Training loss: 450.91, train f1: 0.9988, val loss: 1121.46, val f1: 0.9698, time: 220.37s\n",
            "{'nlayers': 2, 'use_char': True, 'use_pos': False, 'attn_method': 'Dot Product'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning:\n",
            "\n",
            "Couldn't retrieve source code for container of type BiLSTM_CRF. It won't be checked for correctness upon loading.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning:\n",
            "\n",
            "Couldn't retrieve source code for container of type PoSTagger. It won't be checked for correctness upon loading.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'nlayers': 2, 'use_char': True, 'use_pos': False, 'attn_method': 'Dot Product'}\n",
            "Epoch:1, Training loss: 12480.52, train f1: 0.9388, val loss: 1525.73, val f1: 0.9284, time: 257.43s\n",
            "Epoch:2, Training loss: 5198.79, train f1: 0.9610, val loss: 1110.91, val f1: 0.9457, time: 256.46s\n",
            "Epoch:3, Training loss: 3663.09, train f1: 0.9651, val loss: 1253.01, val f1: 0.9464, time: 257.05s\n",
            "Epoch:4, Training loss: 2718.10, train f1: 0.9801, val loss: 1031.46, val f1: 0.9562, time: 257.12s\n",
            "Epoch:5, Training loss: 2061.73, train f1: 0.9821, val loss: 1071.90, val f1: 0.9567, time: 257.00s\n",
            "Epoch:6, Training loss: 1609.68, train f1: 0.9870, val loss: 1122.02, val f1: 0.9625, time: 256.58s\n",
            "Epoch:7, Training loss: 1413.68, train f1: 0.9855, val loss: 1159.78, val f1: 0.9627, time: 258.31s\n",
            "Epoch:8, Training loss: 1286.19, train f1: 0.9912, val loss: 1064.41, val f1: 0.9668, time: 263.43s\n",
            "Epoch:9, Training loss: 1032.25, train f1: 0.9929, val loss: 1105.16, val f1: 0.9647, time: 260.74s\n",
            "Epoch:10, Training loss: 1016.33, train f1: 0.9956, val loss: 1024.10, val f1: 0.9704, time: 261.19s\n",
            "Epoch:11, Training loss: 683.06, train f1: 0.9973, val loss: 970.14, val f1: 0.9718, time: 263.84s\n",
            "Epoch:12, Training loss: 609.25, train f1: 0.9980, val loss: 995.87, val f1: 0.9729, time: 263.77s\n",
            "Epoch:13, Training loss: 533.99, train f1: 0.9982, val loss: 989.40, val f1: 0.9718, time: 266.26s\n",
            "Epoch:14, Training loss: 464.74, train f1: 0.9979, val loss: 1010.38, val f1: 0.9718, time: 267.90s\n",
            "Epoch:15, Training loss: 430.62, train f1: 0.9985, val loss: 1017.67, val f1: 0.9722, time: 262.79s\n",
            "Epoch:16, Training loss: 415.31, train f1: 0.9981, val loss: 1046.73, val f1: 0.9723, time: 259.53s\n",
            "Epoch:17, Training loss: 414.79, train f1: 0.9989, val loss: 1068.13, val f1: 0.9725, time: 259.17s\n",
            "Epoch:18, Training loss: 397.78, train f1: 0.9989, val loss: 1069.82, val f1: 0.9719, time: 260.17s\n",
            "Epoch:19, Training loss: 348.00, train f1: 0.9990, val loss: 1064.59, val f1: 0.9713, time: 255.27s\n",
            "Epoch:20, Training loss: 375.77, train f1: 0.9989, val loss: 1084.05, val f1: 0.9722, time: 255.13s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj7ANbv_jSzI"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIh-mWrvi6Pw"
      },
      "source": [
        "y_pred= predict(model,test_input_index)\n",
        "\n",
        "def decode_output(output_list):\n",
        "    ix_to_tag = {v:k for k,v in tag_to_ix.items()}\n",
        "    return [ix_to_tag[output] for output in output_list]\n",
        "\n",
        "# y_true_decode = decode_output(y_true)\n",
        "y_pred_decode = decode_output(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZgS0IFW2VxK"
      },
      "source": [
        "submission_df = pd.DataFrame(dict(Id=range(len(y_pred_decode)),Predicted=y_pred_decode))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCJ6BzQX4j_e"
      },
      "source": [
        "submission_df.to_csv('submission.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}