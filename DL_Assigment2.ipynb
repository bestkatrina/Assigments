{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Assigment2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "26f22ba3eacc42a8bdd874a1657d8a43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_679c1698c5b845f6a1e445c2d0af3524",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_756774f8fb744e38a90d1ef65d9e78f7",
              "IPY_MODEL_8a3ff0080a694a24bea570ea69f3d778"
            ]
          }
        },
        "679c1698c5b845f6a1e445c2d0af3524": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "756774f8fb744e38a90d1ef65d9e78f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d9acfd7a94064e2a98f72f5b1981b137",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 100441675,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100441675,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ed486df5a0114a32adcae7d49cc7ff4d"
          }
        },
        "8a3ff0080a694a24bea570ea69f3d778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_34275b7ce2c54152b423ef72fb3990b7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 95.8M/95.8M [00:01&lt;00:00, 63.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8dfe826ac6894416a0d993fe2c50c3e8"
          }
        },
        "d9acfd7a94064e2a98f72f5b1981b137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ed486df5a0114a32adcae7d49cc7ff4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "34275b7ce2c54152b423ef72fb3990b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8dfe826ac6894416a0d993fe2c50c3e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P5fKXxHB8uK"
      },
      "source": [
        "## 0.Download dataset from google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oc0pXZ2K33m8",
        "outputId": "ca740749-24e1-4a98-fa1f-9830e45f4192",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "# Code to download file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "id = '1_6kHRoaob9xdO45ReB9hXOxlUr7IGOFK'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('2020s1comp5329assignment2.zip')\n",
        "if not os.path.exists('/content/COMP5329S1A2Dataset'):\n",
        "    !unzip -d /content/ /content/2020s1comp5329assignment2.zip > /dev/null\n",
        "    print('File unzipped')\n",
        "else:\n",
        "    print('File existed')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File unzipped\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2bVzrnHCneV"
      },
      "source": [
        "## 1.Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXtKPidmP2DE",
        "outputId": "c02aedbe-02e6-461a-97a1-fb9323aaea7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Acquire file names and corresponding labels from train.csv and test.csv\n",
        "import re\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "import numpy as np\n",
        "data_path = \"/content/COMP5329S1A2Dataset/\"\n",
        "with open(data_path + 'train.csv','r') as f:\n",
        "  # Caption texts contain '/', so '|' is used for excapechar.\n",
        "  lines = [re.sub(r'([^,])\"(\\s*[^\\n])', r'\\1|\"\\2', line) for line in f]\n",
        "df_train = pd.read_csv(StringIO(''.join(lines)), escapechar=\"|\")\n",
        "train_files = list(map(lambda x: data_path + 'data/' + x, df_train.ImageID.to_list()))\n",
        "train_labels = df_train.Labels.to_list()\n",
        "train_caption = df_train.Caption.to_list()\n",
        "\n",
        "with open(data_path + 'test.csv','r') as f:\n",
        "  lines = [re.sub(r'([^,])\"(\\s*[^\\n])', r'\\1|\"\\2', line) for line in f]\n",
        "df_test = pd.read_csv(StringIO(''.join(lines)), escapechar=\"|\")\n",
        "test_files = list(map(lambda x: data_path + 'data/' + x, df_test.ImageID.to_list()))\n",
        "test_caption = df_test.Caption.to_list()\n",
        "\n",
        "# Acquire the number of classes\n",
        "unique_label = list(set([int(lb) for lbs in train_labels for lb in lbs.split(' ')]))\n",
        "n_classes = len(unique_label)\n",
        "\n",
        "# Create a mapping of labels \n",
        "unique_label.sort()\n",
        "unique_label_dict = {j:i for i,j in enumerate(unique_label)}\n",
        "print('the number of classes: ',n_classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the number of classes:  18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmjTzRh3lDf6"
      },
      "source": [
        "## 2.Data pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_lpfWIxlimC"
      },
      "source": [
        "### 2.1 Train-Validation splt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkla-Pa_lCn8",
        "outputId": "248bbe0d-2b48-44e7-c139-2cf9d14d562e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Train-Validation split. \n",
        "from sklearn.model_selection import train_test_split\n",
        "train_files,val_files,train_caption, val_caption, train_labels, val_labels = train_test_split(train_files, train_caption, train_labels, test_size=0.1, random_state=1)\n",
        "\n",
        "print('size of trainning set: ',len(train_files))\n",
        "print('size of training labels: ',len(train_labels))\n",
        "print('size of validation set: ',len(val_files))\n",
        "print('size of validation labels: ', len(val_labels))\n",
        "print('size of test set: ',len(test_files))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size of trainning set:  27000\n",
            "size of training labels:  27000\n",
            "size of validation set:  3000\n",
            "size of validation labels:  3000\n",
            "size of test set:  10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0LmalXbDMbG"
      },
      "source": [
        "### 2.2 Image transformation & normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_srRChI26znp"
      },
      "source": [
        "from torch.utils.data import Dataset,DataLoader\n",
        "from PIL import Image \n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define customized dataset so that it can be accepted by DataLoader\n",
        "class ImageDataset(Dataset):\n",
        "  def __init__(self,img_names,labels=None,transform=None,target_transform=None):\n",
        "    self.img_names = img_names\n",
        "    self.labels = labels\n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    img_name = self.img_names[index]\n",
        "    img = Image.open(img_name).convert('RGB')\n",
        "    if self.labels:\n",
        "      label = self.labels[index]\n",
        "    else:\n",
        "      label = None\n",
        "    if self.transform:\n",
        "      img =  self.transform(img)\n",
        "    if self.target_transform:\n",
        "      label = self.target_transform(label)\n",
        "      label = torch.from_numpy(label).float()\n",
        "\n",
        "    if self.labels:\n",
        "      return img,label\n",
        "    else:\n",
        "      return img\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XajzX6O9NtaO"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "transform = { \n",
        "    'train': transforms.Compose([\n",
        "        # Resize images\n",
        "        transforms.Resize([256,256]),\n",
        "        # transforms.ColorJitter(brightness=1,saturation=1,contrast=1,hue=0.5),\n",
        "        # Flip images randomly\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        # Crop a random 227x227 area of images \n",
        "        transforms.RandomResizedCrop([224,224]),\n",
        "        # Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] \n",
        "        # to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] \n",
        "        transforms.ToTensor(),\n",
        "        # Nomalization using mean and std\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'validation': transforms.Compose([\n",
        "        transforms.Resize([256,256]),\n",
        "        transforms.CenterCrop([224,224]),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize([256,256]),\n",
        "        transforms.CenterCrop([224,224]),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}\n",
        "import numpy as np\n",
        "def encode_label(label):\n",
        "  # Encode lable to one-hot label\n",
        "  one_hot_label = np.zeros(n_classes)\n",
        "  for l in label.split(' '):\n",
        "    one_hot_label[unique_label_dict[int(l)]] = 1 \n",
        "  return np.array(one_hot_label)\n",
        "\n",
        "def decode_label(one_hot_label):\n",
        "  # Acquire labels from one-hot label\n",
        "  true_classes = [str(ohl * ul) for ohl, ul in zip(one_hot_label,unique_label) if ohl*ul != 0]\n",
        "  true_classes = ' '.join(true_classes)\n",
        "  return true_classes\n",
        "\n",
        "img_batch_size = 128 \n",
        "num_workers = 0 # For our dataset, it costs less training time when \"num_workers\" equals to 0\n",
        "train_dataset = ImageDataset(\n",
        "    img_names=train_files,\n",
        "    labels=train_labels,\n",
        "    transform=transform['train'],\n",
        "    target_transform=encode_label\n",
        ")\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=img_batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "val_dataset = ImageDataset(\n",
        "    img_names=val_files,\n",
        "    labels=val_labels,\n",
        "    transform=transform['validation'],\n",
        "    target_transform=encode_label\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    batch_size=16,\n",
        "    shuffle=False,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "test_dataset = ImageDataset(\n",
        "    img_names=test_files,\n",
        "    transform=transform['test']\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=16,\n",
        "    shuffle=False,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymA4IWASmzPq"
      },
      "source": [
        "### 2.3 Caption texts transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qALSQqK2XIQS"
      },
      "source": [
        "#### 2.3.1 Pre-process caption texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbDwPwi2LNcJ",
        "outputId": "e8b57696-2c71-4977-e1c5-d70dc9dfad5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords as sw\n",
        "from nltk.stem.porter import *\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk import word_tokenize\n",
        "from tqdm import tqdm\n",
        "# Turn list into dict to improve lookup speed\n",
        "stopwords_dict={word:'' for word in sw.words()}\n",
        "def tknzr(caption):\n",
        "  caption_tknzed = list()\n",
        "  for sentence in tqdm(caption):\n",
        "    tmp =list()\n",
        "    for word in word_tokenize(sentence.lower()):\n",
        "      # Remove stop words and punctuations\n",
        "      if re.fullmatch(r'[a-z]+',word)  and word not in stopwords_dict:\n",
        "        tmp.append(word)\n",
        "    caption_tknzed.append(tmp)\n",
        "  return caption_tknzed\n",
        "train_caption_tknzed = tknzr(train_caption)\n",
        "val_caption_tknzed = tknzr(val_caption)\n",
        "test_caption_tknzed = tknzr(test_caption)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27000/27000 [00:03<00:00, 8886.94it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3000/3000 [00:00<00:00, 8856.92it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:01<00:00, 8801.97it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJJgfZzNn4Ge"
      },
      "source": [
        "#### 2.3.2 Acquire word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il3vaRPpOD3I",
        "outputId": "51dd686f-625b-4173-81af-d0897055e683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# From the frequency of different length of captions, \n",
        "# the length of most captions are less than or equal to 10\n",
        "from collections import Counter\n",
        "Counter(map(len,train_caption_tknzed)).most_common()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(5, 7989),\n",
              " (6, 6756),\n",
              " (4, 4892),\n",
              " (7, 3489),\n",
              " (3, 1542),\n",
              " (8, 1380),\n",
              " (9, 446),\n",
              " (2, 194),\n",
              " (10, 163),\n",
              " (11, 68),\n",
              " (12, 31),\n",
              " (13, 16),\n",
              " (1, 10),\n",
              " (14, 8),\n",
              " (15, 7),\n",
              " (17, 3),\n",
              " (16, 2),\n",
              " (19, 2),\n",
              " (21, 1),\n",
              " (27, 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8nwpuyVuGqx",
        "outputId": "6ccff814-249f-41aa-81fb-27f2b9e0323d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Load pre-trained embedding vectors\n",
        "import gensim.downloader as api\n",
        "embedding_model = api.load('glove-wiki-gigaword-300')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[=================================================-] 99.9% 375.8/376.1MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNhIqgR3rhnX",
        "outputId": "07fd9695-41d6-4f97-9183-0bce39a4037c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "def gen_embeddinig(caption_tknzed,embedding_model,padding_size=10):\n",
        "  # The sentence length of all inputs has to be same. \n",
        "  # Long sentences will be truncated and short sentences will be padded.\n",
        "  input_embeddings = []\n",
        "  padding = np.random.uniform(-0.25, 0.25, embedding_model.vectors.shape[1]).round(6)\n",
        "  for sentence in tqdm(caption_tknzed):\n",
        "    tmp_embeddings = []\n",
        "    for idx in range(padding_size):\n",
        "      try:\n",
        "        tmp_embeddings.append(embedding_model.get_vector(sentence[idx]))\n",
        "      except:\n",
        "        tmp_embeddings.append(padding)\n",
        "    input_embeddings.append(tmp_embeddings)\n",
        "  return np.array(input_embeddings)\n",
        "train_embeddings = gen_embeddinig(train_caption_tknzed,embedding_model)\n",
        "val_embeddings = gen_embeddinig(val_caption_tknzed,embedding_model)\n",
        "test_embeddings = gen_embeddinig(test_caption_tknzed,embedding_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27000/27000 [00:00<00:00, 67587.40it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3000/3000 [00:00<00:00, 112466.92it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:00<00:00, 120271.61it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvzAWhWaHtJy"
      },
      "source": [
        "from torch.utils.data import Dataset,DataLoader\n",
        "# define customized dataset so that it can be accepted by DataLoader\n",
        "class EmbeddingDataset(Dataset):\n",
        "  def __init__(self,embeddings,labels=None,transform=None,target_transform=None):\n",
        "    self.embeddings = embeddings\n",
        "    self.labels = labels\n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    embedding = self.embeddings[index]\n",
        "    embedding = torch.from_numpy(embedding).float()\n",
        "    if self.labels:\n",
        "      label = self.labels[index]\n",
        "    else:\n",
        "      label = None\n",
        "    if self.transform:\n",
        "      img =  self.transform(img)\n",
        "    if self.target_transform:\n",
        "      label = self.target_transform(label)\n",
        "      label = torch.from_numpy(label).float()\n",
        "\n",
        "    if self.labels:\n",
        "      return embedding,label\n",
        "    else:\n",
        "      return embedding\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.embeddings)\n",
        "\n",
        "emb_batch_size = 64\n",
        "num_workers = 0\n",
        "train_emb_dataset = EmbeddingDataset(\n",
        "    embeddings=train_embeddings,\n",
        "    labels=train_labels,\n",
        "    target_transform=encode_label\n",
        ")\n",
        "train_emb_loader = DataLoader(\n",
        "    dataset=train_emb_dataset,\n",
        "    batch_size=emb_batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "val_emb_dataset = EmbeddingDataset(\n",
        "    embeddings=val_embeddings,\n",
        "    labels=val_labels,\n",
        "    target_transform=encode_label\n",
        ")\n",
        "val_emb_loader = DataLoader(\n",
        "    dataset=val_emb_dataset,\n",
        "    batch_size=emb_batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "test_emb_dataset = EmbeddingDataset(\n",
        "    embeddings=test_embeddings\n",
        ")\n",
        "test_emb_loader = DataLoader(\n",
        "    dataset=test_emb_dataset,\n",
        "    batch_size=emb_batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bohzKSPuJWih"
      },
      "source": [
        "\n",
        "## 3.Define classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWgxpKtqpYJe"
      },
      "source": [
        "This class provides interfaces for model training, prediction and plotting curves."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0ThMLKZutAH"
      },
      "source": [
        "from sklearn.metrics import accuracy_score,f1_score\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "import time\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "class Classifier(object):\n",
        "  def __init__(self,model,loss_func=None,optimizer=None,lr_scheduler=None):\n",
        "    self.model = model\n",
        "    self.criterion = loss_func\n",
        "    self.optimizer = optimizer\n",
        "    self.lr_scheduler = lr_scheduler\n",
        "    self.logs = {\n",
        "        'epoch':[],\n",
        "        'batch':[],\n",
        "        'lr':[],\n",
        "        'train_loss':[],\n",
        "        'train_acc':[],\n",
        "        'train_f1_score':[],\n",
        "        'val_loss':[],\n",
        "        'val_acc':[],\n",
        "        'val_f1_score':[],    \n",
        "      }\n",
        "  def model_name(self):\n",
        "    return self.model.__class__.__name__\n",
        "  def fit(self,epochs,train_loader,val_loader,show_interval,lr_scheduler_on=True):\n",
        "    for epoch in range(epochs): \n",
        "      print('Epoch: ',epoch + 1)\n",
        "      start_time = time.time()  \n",
        "      # forward + backward + optimize\n",
        "      train_loss = list()\n",
        "      train_preds = list()\n",
        "      train_targets =list()\n",
        "      for i,(X,y) in enumerate(train_loader):\n",
        "        # Set the flag to training\n",
        "        self.model.train()\n",
        "        input_batch_torch = X.to(device)\n",
        "        target_batch_torch = y.to(device)\n",
        "        outputs = self.model(input_batch_torch)\n",
        "        loss = self.criterion(outputs, target_batch_torch)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        self.optimizer.zero_grad()\n",
        "        # Set the flag to evaluation, which will 'turn off' the dropout\n",
        "        self.model.eval()\n",
        "        # Calculate metrics on training set\n",
        "        with torch.no_grad():\n",
        "          outputs = self.model(input_batch_torch) \n",
        "          loss = self.criterion(outputs, target_batch_torch).item()\n",
        "          train_loss.append(loss)\n",
        "          train_preds += torch.round(nn.Sigmoid()(outputs)).cpu().detach().numpy().astype(int).tolist()\n",
        "          train_targets += target_batch_torch.cpu().numpy().astype(int).tolist()\n",
        "\n",
        "\n",
        "\n",
        "          if i%show_interval == show_interval-1:\n",
        "\n",
        "            train_loss = np.mean(train_loss)\n",
        "            train_acc = accuracy_score(train_targets,train_preds)\n",
        "            train_f1_score = f1_score(train_targets,train_preds,average='samples')\n",
        "\n",
        "            # Calculate metrics on validation set\n",
        "            val_loss = list()\n",
        "            val_preds = list()\n",
        "            val_targets = list()\n",
        "            for val_X,val_y in val_loader:\n",
        "              val_X_torch = val_X.to(device)\n",
        "              val_y_torch = val_y.to(device)\n",
        "              outputs = self.model(val_X_torch)\n",
        "              loss = self.criterion(outputs, val_y_torch).item()\n",
        "              val_loss.append(loss)\n",
        "              val_preds += torch.round(nn.Sigmoid()(outputs)).cpu().detach().numpy().astype(int).tolist()\n",
        "              val_targets += val_y_torch.cpu().numpy().astype(int).tolist()\n",
        "\n",
        "            val_loss = np.mean(val_loss)\n",
        "            val_acc = accuracy_score(val_targets,val_preds)\n",
        "            val_f1_score = f1_score(val_targets,val_preds,average='samples')\n",
        "            end_time = time.time()\n",
        "            print(' Batch: %d, train_loss: %.5f, train_acc: %.4f, tran_f1_score: %.4f \\n val_loss: %.5f, val_acc: %.4f, val_f1_score: %.4f, time_elapsed: %.2f' \n",
        "                %(i + 1, train_loss, train_acc, train_f1_score, val_loss, val_acc, val_f1_score, end_time - start_time))\n",
        "\n",
        "            # Save the scores to plot \n",
        "\n",
        "            self.logs['epoch'].append(epoch + 1)\n",
        "            self.logs['batch'].append(i+1)\n",
        "            self.logs['lr'].append(self.optimizer.__dict__['param_groups'][0]['lr'])\n",
        "            self.logs['train_loss'].append(train_loss)\n",
        "            self.logs['train_acc'].append(train_acc)\n",
        "            self.logs['train_f1_score'].append(train_f1_score)\n",
        "            self.logs['val_loss'].append(val_loss)\n",
        "            self.logs['val_acc'].append(val_acc)\n",
        "            self.logs['val_f1_score'].append(val_f1_score)\n",
        "            train_loss = list()\n",
        "            train_preds = list()\n",
        "            train_targets = list()\n",
        "      print('Total time this epoch: ', time.time() - start_time)\n",
        "      if self.lr_scheduler and lr_scheduler_on:\n",
        "        self.lr_scheduler.step()\n",
        "    print('Finished Training')\n",
        "  def validate(self,loader):\n",
        "    self.model.eval()\n",
        "    preds = list()\n",
        "    targets = list()\n",
        "    preds_prob = list()\n",
        "    preds_org = list()\n",
        "    with torch.no_grad():\n",
        "      for X,y in loader:\n",
        "        X_torch = X.to(device)\n",
        "        y_torch = y.to(device)\n",
        "        outputs = self.model(X_torch)\n",
        "        preds_org += outputs.cpu().detach().numpy().tolist()\n",
        "        preds_prob += nn.Sigmoid()(outputs).cpu().detach().numpy().tolist()\n",
        "        preds += torch.round(nn.Sigmoid()(outputs)).cpu().detach().numpy().astype(int).tolist()\n",
        "        targets += y_torch.cpu().numpy().astype(int).tolist()\n",
        "    f1 = f1_score(targets,preds,average='samples')\n",
        "\n",
        "    return preds,preds_prob,preds_org,targets,f1\n",
        "  def get_output(self,x):\n",
        "    return self.model(x).cpu().detach().numpy().tolist()\n",
        "  def predict(self,loader):\n",
        "    self.model.eval()\n",
        "    preds = list()\n",
        "    preds_prob = list()\n",
        "    preds_org = list()\n",
        "    for X in loader:\n",
        "      X_torch = X.to(device)\n",
        "      outputs = self.model(X_torch)\n",
        "      preds_org += outputs.cpu().detach().numpy().tolist()\n",
        "      preds_prob += nn.Sigmoid()(outputs).cpu().detach().numpy().tolist()\n",
        "      preds += torch.round(nn.Sigmoid()(outputs)).cpu().detach().numpy().astype(int).tolist()\n",
        "    return preds,preds_prob,preds_org\n",
        "  def save_model(self,path='./'):\n",
        "    full_path = path + self.model.__class__.__name__ + '.pt'\n",
        "    torch.save(self.model,full_path)\n",
        "  def logs(self):\n",
        "    return self.logs\n",
        "  def plot(self,initial_lr,batch_size,save_dir='./'):\n",
        "    df = pd.DataFrame(self.logs)\n",
        "    df.to_csv(save_dir + '{}_{}_{}.log'.format(self.model_name(),initial_lr,batch_size),index=False)\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=df.index, y=df.train_loss,mode='lines+markers',name='training loss')) \n",
        "    fig.add_trace(go.Scatter(x=df.index, y=df.val_loss,mode='lines+markers',name='validation loss'))\n",
        "    fig.show()\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=df.index, y=df.train_acc,mode='lines+markers',name='training accuracy')) \n",
        "    fig.add_trace(go.Scatter(x=df.index, y=df.val_acc,mode='lines+markers',name='validation accuracy'))\n",
        "    fig.show()\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=df.index, y=df.train_f1_score,mode='lines+markers',name='training f1 score')) \n",
        "    fig.add_trace(go.Scatter(x=df.index, y=df.val_f1_score,mode='lines+markers',name='validation f1 score'))\n",
        "    fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uv0DDv-VZkF4"
      },
      "source": [
        "## 4.Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvEgrPVjqbTV"
      },
      "source": [
        "### 4.1 ResNeXt50_32x4d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8folztYlZurl",
        "outputId": "997cbecb-49b9-4f04-82bf-6a9fa5537027",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "26f22ba3eacc42a8bdd874a1657d8a43",
            "679c1698c5b845f6a1e445c2d0af3524",
            "756774f8fb744e38a90d1ef65d9e78f7",
            "8a3ff0080a694a24bea570ea69f3d778",
            "d9acfd7a94064e2a98f72f5b1981b137",
            "ed486df5a0114a32adcae7d49cc7ff4d",
            "34275b7ce2c54152b423ef72fb3990b7",
            "8dfe826ac6894416a0d993fe2c50c3e8"
          ]
        }
      },
      "source": [
        "from torchvision import models \n",
        "import torch.nn as nn\n",
        "# Load pre-trained model\n",
        "pre_train_model = models.resnext50_32x4d(pretrained=True)\n",
        "dropout = True\n",
        "# Modify the full connected layers of ResNext\n",
        "in_features = pre_train_model.fc.in_features\n",
        "fc_layers = list()\n",
        "if dropout:\n",
        "  fc_layers.append(nn.Dropout(p=0.5,inplace=True))\n",
        "fc_layers.append(nn.Linear(in_features,n_classes,bias=True))\n",
        "pre_train_model.fc = nn.Sequential(*fc_layers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /root/.cache/torch/checkpoints/resnext50_32x4d-7cdf4587.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26f22ba3eacc42a8bdd874a1657d8a43",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=100441675.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD8KfdDuqsCi"
      },
      "source": [
        "### 4.2 LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rOsLgJJqvnf"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self,):\n",
        "        super(LSTM, self).__init__()\n",
        "\n",
        "        self.lstm = nn.LSTM(300,256,num_layers=3,batch_first =True,dropout=0.5)\n",
        "        self.linear_layers = nn.Sequential(\n",
        "            nn.Linear(256,18,bias=True),\n",
        "        )\n",
        "\n",
        "    def forward(self,x_emb):\n",
        "        x_emb,_ = self.lstm(x_emb)\n",
        "        x_emb = x_emb[:,-1,:]\n",
        "        x = self.linear_layers(x_emb)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Wi0FLrYq9JT"
      },
      "source": [
        "## 5.Train process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Eyrd-9IrAna"
      },
      "source": [
        "### 5.1 Train with ResNeXt50_32x4d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftvzLq6wZuru"
      },
      "source": [
        "# Setting hyperparameters\n",
        "epochs = 15\n",
        "learning_rate = 0.08\n",
        "momentum = 0.9\n",
        "pre_train_model = pre_train_model.to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.SGD(pre_train_model.parameters(),lr=learning_rate,momentum=momentum,nesterov=True)\n",
        "learning_rate_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=3,gamma=0.1)\n",
        "# Initialization\n",
        "model = Classifier(pre_train_model,loss_func=criterion,optimizer=optimizer,lr_scheduler=learning_rate_scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMKGAWrjZury"
      },
      "source": [
        "# Train model\n",
        "model.fit(epochs=epochs,train_loader=train_loader,val_loader=val_loader,show_interval=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YamdCOlwZur2"
      },
      "source": [
        "# Save model\n",
        "model.save_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXKhYLrZrM0_"
      },
      "source": [
        "### 5.2 Train with LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRCeKRcYJ_mG"
      },
      "source": [
        "net = LSTM().to(device)\n",
        "# Setting hyperparameters\n",
        "epochs = 30\n",
        "learning_rate = 0.0005\n",
        "momentum = 0.9\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "# Try different optimizer\n",
        "# optimizer = optim.SGD(net.parameters(),lr=learning_rate,momentum=momentum,nesterov=True)\n",
        "optimizer = optim.AdamW(net.parameters(),lr=learning_rate,weight_decay=0.5)\n",
        "# Try different learning rate scheduler\n",
        "# learning_rate_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[15,30],gamma=0.1)\n",
        "learning_rate_sheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=30)\n",
        "# Initialization\n",
        "model = Classifier(net,loss_func=criterion,optimizer=optimizer,\n",
        "                    lr_scheduler=learning_rate_sheduler\n",
        "                   )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pO_copFDJ_mT"
      },
      "source": [
        "# Train model\n",
        "model.fit(epochs=epochs,train_loader=train_emb_loader,val_loader=val_emb_loader,show_interval=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR2HYxxat003",
        "outputId": "93fc89ca-f08a-4d49-e5ce-f93da9d95397",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "model.save_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning:\n",
            "\n",
            "Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEfJ8NFdRAxB"
      },
      "source": [
        "### 5.3 Ensemble ResNext and LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yop0Ieq-2-cN"
      },
      "source": [
        "#### 5.3.1 Acquire the outputs of ResNext and LSTM on validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4g_hH_6cBBfv"
      },
      "source": [
        "# Load model from file\n",
        "id = '1V0WJl4_c92-JQi6TkpIXFdHHE-_P1Wck'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('ResNext50.pt')\n",
        "resnext50 = torch.load('/content/ResNext50.pt')\n",
        "res_model = Classifier(resnext50)\n",
        "preds_res,preds_res_prob,preds_res_org,targets,res_f1 = res_model.validate(val_loader) #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3VDbuAWFEEj"
      },
      "source": [
        "id = '1JyOH9gnxUE2GEUP0X0mKKeSpPBpUciiW'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('LSTM.pt')\n",
        "net = torch.load('/content/LSTM.pt')\n",
        "emb_model = Classifier(net)\n",
        "preds_emb,preds_emb_prob,preds_emb_org,targets,emb_f1 = emb_model.validate(val_emb_loader) #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8AJfVrOt-Wm",
        "outputId": "d4fd3be0-1929-4d6d-de89-e5cc55e9f6a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "res_f1,emb_f1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8616196488696488, 0.8218759259259261)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENixTFruf1ti"
      },
      "source": [
        "#### 5.3.2 Stacking Ensemble of the two **models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uYgDixi4z3C",
        "outputId": "0559bc0b-8536-4777-9bd7-7f5f70393fb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "print(np.array(preds_res_org).shape)\n",
        "print(np.array(preds_emb_org).shape) \n",
        "# Concentate the outputs of ResNeXt50_32x4d and LSTM models\n",
        "# The concentated has the shape of [N,n_classes * 2]\n",
        "X_stacking = np.concatenate((np.array(preds_res_org),np.array(preds_emb_org)),axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3000, 18)\n",
            "(3000, 18)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFNNRoEDumsG",
        "outputId": "787a8109-2a29-4c19-ac54-9750acf8d80d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "# Search for optimal hyperparameters for RF classfifier\n",
        "parameters = {'estimator__n_estimators':np.arange(100,1500,200), \n",
        "              'estimator__max_features':[\"auto\",\"sqrt\",\"log2\"],\n",
        "              'estimator__class_weight':['balanced',None],\n",
        "              'estimator__n_jobs':[4]}\n",
        "rf =  MultiOutputClassifier(RandomForestClassifier())\n",
        "clf = GridSearchCV(rf, parameters,cv=3,n_jobs=4,verbose=1,scoring='f1_samples')\n",
        "clf.fit(np.array(X_stacking), np.array(targets))\n",
        "\n",
        "print('best score: ',clf.best_score_)\n",
        "print('best estimator: ',clf.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 42 candidates, totalling 126 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed: 15.4min\n",
            "[Parallel(n_jobs=4)]: Done 126 out of 126 | elapsed: 50.6min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "best score:  0.8731854978354979\n",
            "best estimator:  MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True,\n",
            "                                                       ccp_alpha=0.0,\n",
            "                                                       class_weight=None,\n",
            "                                                       criterion='gini',\n",
            "                                                       max_depth=None,\n",
            "                                                       max_features='sqrt',\n",
            "                                                       max_leaf_nodes=None,\n",
            "                                                       max_samples=None,\n",
            "                                                       min_impurity_decrease=0.0,\n",
            "                                                       min_impurity_split=None,\n",
            "                                                       min_samples_leaf=1,\n",
            "                                                       min_samples_split=2,\n",
            "                                                       min_weight_fraction_leaf=0.0,\n",
            "                                                       n_estimators=900,\n",
            "                                                       n_jobs=4,\n",
            "                                                       oob_score=False,\n",
            "                                                       random_state=None,\n",
            "                                                       verbose=0,\n",
            "                                                       warm_start=False),\n",
            "                      n_jobs=None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNuaR42KhSCB",
        "outputId": "c0314073-2fa2-4b0f-b722-ab5490a1cbf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Take 2000 samples as training set of RF classifier from validation set. \n",
        "# Other 1000 samples are leftover for validation set of RF classifier.\n",
        "start = time.time()\n",
        "X = X_stacking[:2000]\n",
        "y = targets[:2000]\n",
        "rf = MultiOutputClassifier(RandomForestClassifier(n_estimators=900,max_features='sqrt',n_jobs=4)).fit(X,y)\n",
        "preds_stacking = rf.predict(X_stacking[2000:])\n",
        "\n",
        "end = time.time()\n",
        "print('Training time: ',end - start)\n",
        "print('Score of stacking ensemble model: ', f1_score(targets[2000:],preds_stacking,average='samples'))\n",
        "print('Score of single model - ResNext: ', f1_score(targets[2000:],preds_res[2000:],average='samples'))\n",
        "print('Sore of single model - LSTM: ', f1_score(targets[2000:],preds_emb[2000:],average='samples'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training time:  53.778677463531494\n",
            "Score of stacking ensemble model:  0.864554329004329\n",
            "Score of single model - ResNext:  0.8539420634920636\n",
            "Sore of single model - LSTM:  0.8301761904761904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acYLCwa76P4L"
      },
      "source": [
        "#### 5.3.3 Weighted Average Ensemble of the two models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4s1eEYhX66SF"
      },
      "source": [
        "##### 5.3.3.1 Find optimal weight and threshold via differential evolution algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N09u2kKGgsVU",
        "outputId": "81baa066-feff-4e1d-e49d-701c4b9bed6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from scipy.optimize import differential_evolution\n",
        "def predict_by_threshold(preds_probs,threshold):\n",
        "  return list(map(lambda probs:[1  if prob >= threshold else 0 for prob in probs],preds_probs))\n",
        "def target_func(x):\n",
        "  w = x[:2]\n",
        "  # Ensure the sum of weight values equal to 1\n",
        "  result = np.linalg.norm(w,1)\n",
        "  if result != 0.0:\n",
        "    w /= result\n",
        "  w1 = w[0]\n",
        "  w2 = w[1]\n",
        "  th = x[2:]\n",
        "  preds_weighted = np.array(preds_res_org) * w1 + np.array(preds_emb_org) * w2\n",
        "  f1 = f1_score(predict_by_threshold(nn.Sigmoid()(torch.from_numpy(preds_weighted)).numpy(),th),targets,average='samples')\n",
        "  return 1 - f1\n",
        "bound_weight = [(0.0,1.0)] * 3\n",
        "result = differential_evolution(target_func,bound_weight,maxiter=1000)\n",
        "w = result.x[:2]\n",
        "w /= np.linalg.norm(w,1)\n",
        "w1 = w[0]\n",
        "w2 = w[1]\n",
        "threshold = result.x[2:]\n",
        "best_socre = 1 - result.fun\n",
        "print('Optimal solution: ',result.x)\n",
        "print('Best score: ',best_socre)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimal solution:  [0.65043697 0.34956303 0.33409821]\n",
            "Best score:  0.8797013708513708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcdSRkDPpE0A",
        "outputId": "6b96f2f8-c0f3-4c68-d2b8-176f126327bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "preds_weighted = np.array(preds_res_org) * w1 + np.array(preds_emb_org) * w2 #+ np.array(preds_emb_org_1) * w3\n",
        "weighted_f1 = f1_score(predict_by_threshold(nn.Sigmoid()(torch.from_numpy(preds_weighted)).numpy(),threshold),np.array(targets),average='samples')\n",
        "\n",
        "print('Score of weighted ensemble model: ', weighted_f1)\n",
        "print('Score of single model - ResNext: ', res_f1)\n",
        "print('Sore of single model - LSTM: ', emb_f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score of weighted ensemble model:  0.8797013708513708\n",
            "Score of single model - ResNext:  0.8616196488696488\n",
            "Sore of single model - LSTM:  0.8269235449735449\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tfzp-NN7B2GZ"
      },
      "source": [
        "## 6.Predict on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiXopo42eBjQ"
      },
      "source": [
        "# Load model from file\n",
        "id = '1V0WJl4_c92-JQi6TkpIXFdHHE-_P1Wck'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('ResNext50.pt')\n",
        "resnext50 = torch.load('/content/ResNext50.pt')\n",
        "res_model = Classifier(resnext50)\n",
        "# Predict labels\n",
        "preds_res,preds_res_prob,preds_res_org = res_model.predict(test_loader) #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQfy67073bDd"
      },
      "source": [
        "id = '1JyOH9gnxUE2GEUP0X0mKKeSpPBpUciiW'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('LSTM.pt')\n",
        "net = torch.load('/content/LSTM.pt')\n",
        "emb_model = Classifier(net)\n",
        "preds_emb,preds_emb_prob,preds_emb_org = emb_model.predict(test_emb_loader) #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTmVnISaCK1p"
      },
      "source": [
        "def predict_by_threshold(preds_probs,threshold):\n",
        "  return list(map(lambda probs:[1  if prob >= threshold else 0 for prob in probs],preds_probs))\n",
        "\n",
        "w1 = 0.65043697 \n",
        "w2 = 0.34956303 \n",
        "threshold = 0.33409821\n",
        "preds_weighted = np.array(preds_res_org) * w1 + np.array(preds_emb_org) * w2\n",
        "final_preds = predict_by_threshold(nn.Sigmoid()(torch.from_numpy(preds_weighted)).numpy(),threshold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi_WlBkvCK17"
      },
      "source": [
        "# Decode one-hot label and save as a file\n",
        "predictions = list(map(decode_label,final_preds))\n",
        "image_id = list(map(lambda x:x.split('/')[-1],test_files))\n",
        "df_submission = pd.DataFrame(dict(ImageID=image_id,Labels=predictions))\n",
        "df_submission.to_csv('/content/Predicted_labels.txt',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}